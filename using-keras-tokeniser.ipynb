{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    tags=[]\n",
    "    sentence_tags = []\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in open(filepath, encoding='utf-8'):\n",
    "        if line !='\\n':\n",
    "            word, tag = line.strip().split()\n",
    "            if word.startswith('http://') or word.startswith('https://'):\n",
    "                word = '<URL>'\n",
    "            if word.startswith('@'):\n",
    "                word = '<USR>'\n",
    "            sentence.append(word)\n",
    "            sentence_tags.append(tag)\n",
    "        if line == '\\n':\n",
    "            sentences.append(sentence)\n",
    "            tags.append(sentence_tags)\n",
    "            sentence = []\n",
    "            sentence_tags = []\n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents, train_tags = read_file('data/train.txt')\n",
    "val_sents, val_tags = read_file('data/validation.txt')\n",
    "test_sents, test_tags = read_file('data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ----> B-product\n",
      "MacBook ----> I-product\n",
      "Pro ----> I-product\n",
      "A1278 ----> I-product\n",
      "13.3 ----> I-product\n",
      "\" ----> I-product\n",
      "Laptop ----> I-product\n",
      "- ----> I-product\n",
      "MD101LL/A ----> I-product\n",
      "( ----> O\n",
      "June ----> O\n",
      ", ----> O\n",
      "2012 ----> O\n",
      ") ----> O\n",
      "- ----> O\n",
      "Full ----> O\n",
      "read ----> O\n",
      "by ----> O\n",
      "eBay ----> B-company\n",
      "<URL> ----> O\n",
      "<URL> ----> O\n"
     ]
    }
   ],
   "source": [
    "for word, tag in zip(train_sents[1], train_tags[1]):\n",
    "    print(f\"{word} ----> {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sent_tokenizer = Tokenizer(lower=False, oov_token='<UNK>')\n",
    "sent_tokenizer.fit_on_texts(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "len_dict = defaultdict(int)\n",
    "for sent in train_sents:\n",
    "    len_dict[len(sent)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lens_, counts_ = [], []\n",
    "for len_, count_ in len_dict.items():\n",
    "        lens_.append(len_)\n",
    "        counts_.append(count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 40 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(lens_, counts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming max len as 40\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_len=40\n",
    "train_sequences = sent_tokenizer.texts_to_sequences(train_sents)\n",
    "train_sequences_padded = pad_sequences(train_sequences, padding='post', maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequences = sent_tokenizer.texts_to_sequences(val_sents)\n",
    "val_sequences_padded = pad_sequences(val_sequences, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer(lower=False)\n",
    "tag_tokenizer.fit_on_texts(train_tags)\n",
    "train_tag_sequences = tag_tokenizer.texts_to_sequences(train_tags)\n",
    "train_tag_sequences_padded = pad_sequences(train_tag_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "val_tag_sequences = tag_tokenizer.texts_to_sequences(val_tags)\n",
    "val_tag_sequences_padded = pad_sequences(val_tag_sequences, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9,    2,    5, ...,    0,    0,    0],\n",
       "       [ 622, 6026, 1742, ...,    0,    0,    0],\n",
       "       [ 126,  662,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [5952, 5953, 5954, ...,    0,    0,    0],\n",
       "       [ 210, 2659,   93, ...,    0,    0,    0],\n",
       "       [   2,    7, 1406, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, ...,  0,  0,  0],\n",
       "       [10,  7,  7, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  1,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(sent_tokenizer.word_index) + 1 #including the padding(0 value) as well\n",
    "classes = len(tag_tokenizer.word_index) + 1 # considering the padding class as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding, Dropout\n",
    "from keras.layers import TimeDistributed, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, mask_zero=True, input_length=max_len ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 40, 256)           4857600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 40, 200)           285600    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 40, 200)           240800    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 40, 22)            4422      \n",
      "=================================================================\n",
      "Total params: 5,388,422\n",
      "Trainable params: 5,388,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/20\n",
      "5795/5795 [==============================] - 46s 8ms/step - loss: 0.6381 - acc: 0.9186 - val_loss: 0.4057 - val_acc: 0.9265\n",
      "Epoch 2/20\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.3453 - acc: 0.9248 - val_loss: 0.3221 - val_acc: 0.9277\n",
      "Epoch 3/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.2443 - acc: 0.9329 - val_loss: 0.3201 - val_acc: 0.9263\n",
      "Epoch 4/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.2026 - acc: 0.9414 - val_loss: 0.3235 - val_acc: 0.9282\n",
      "Epoch 5/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.1773 - acc: 0.9480 - val_loss: 0.3283 - val_acc: 0.9221\n",
      "Epoch 6/20\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.1506 - acc: 0.9569 - val_loss: 0.3331 - val_acc: 0.9224\n",
      "Epoch 7/20\n",
      "5795/5795 [==============================] - 40s 7ms/step - loss: 0.1215 - acc: 0.9657 - val_loss: 0.3425 - val_acc: 0.9226\n",
      "Epoch 8/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0942 - acc: 0.9732 - val_loss: 0.3462 - val_acc: 0.9252\n",
      "Epoch 9/20\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.0721 - acc: 0.9791 - val_loss: 0.3792 - val_acc: 0.9337\n",
      "Epoch 10/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0552 - acc: 0.9841 - val_loss: 0.3791 - val_acc: 0.9221\n",
      "Epoch 11/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0389 - acc: 0.9890 - val_loss: 0.3825 - val_acc: 0.9236\n",
      "Epoch 12/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0285 - acc: 0.9923 - val_loss: 0.4097 - val_acc: 0.9191\n",
      "Epoch 13/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0216 - acc: 0.9943 - val_loss: 0.4059 - val_acc: 0.9307\n",
      "Epoch 14/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0158 - acc: 0.9959 - val_loss: 0.4334 - val_acc: 0.9257\n",
      "Epoch 15/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.4361 - val_acc: 0.9245\n",
      "Epoch 16/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.4469 - val_acc: 0.9296\n",
      "Epoch 17/20\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.4663 - val_acc: 0.9232\n",
      "Epoch 18/20\n",
      "5795/5795 [==============================] - 41s 7ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.4707 - val_acc: 0.9249\n",
      "Epoch 19/20\n",
      "5795/5795 [==============================] - 40s 7ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.4700 - val_acc: 0.9220\n",
      "Epoch 20/20\n",
      "5795/5795 [==============================] - 40s 7ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.4803 - val_acc: 0.9261\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=20,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(val_sequences_padded[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tag_sequences_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly Over fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, mask_zero=True, input_length=max_len ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/5\n",
      "5795/5795 [==============================] - 46s 8ms/step - loss: 0.6444 - acc: 0.9185 - val_loss: 0.4106 - val_acc: 0.9265\n",
      "Epoch 2/5\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.3503 - acc: 0.9246 - val_loss: 0.3250 - val_acc: 0.9293\n",
      "Epoch 3/5\n",
      "5795/5795 [==============================] - 38s 7ms/step - loss: 0.2556 - acc: 0.9310 - val_loss: 0.3231 - val_acc: 0.9301\n",
      "Epoch 4/5\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.2152 - acc: 0.9390 - val_loss: 0.3079 - val_acc: 0.9304\n",
      "Epoch 5/5\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.1912 - acc: 0.9444 - val_loss: 0.3169 - val_acc: 0.9340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=5,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(val_sequences_padded[170].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, mask_zero=True, input_length=max_len ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/5\n",
      "5795/5795 [==============================] - 43s 7ms/step - loss: 0.8077 - acc: 0.9134 - val_loss: 0.4525 - val_acc: 0.9265\n",
      "Epoch 2/5\n",
      "5795/5795 [==============================] - 34s 6ms/step - loss: 0.4160 - acc: 0.9236 - val_loss: 0.3562 - val_acc: 0.9265\n",
      "Epoch 3/5\n",
      "5795/5795 [==============================] - 34s 6ms/step - loss: 0.3010 - acc: 0.9246 - val_loss: 0.3365 - val_acc: 0.9282\n",
      "Epoch 4/5\n",
      "5795/5795 [==============================] - 34s 6ms/step - loss: 0.2633 - acc: 0.9280 - val_loss: 0.3420 - val_acc: 0.9283\n",
      "Epoch 5/5\n",
      "5795/5795 [==============================] - 34s 6ms/step - loss: 0.2471 - acc: 0.9305 - val_loss: 0.3366 - val_acc: 0.9278\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=5,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(val_sequences_padded[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7, 7, 7, 1, 7, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(train_sequences_padded[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7,  7,  7,  7,  7,  7,  7,  7,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  6,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_sequences_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, mask_zero=False, input_length=max_len ))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/5\n",
      "5795/5795 [==============================] - 41s 7ms/step - loss: 0.5824 - acc: 0.9113 - val_loss: 0.2002 - val_acc: 0.9692\n",
      "Epoch 2/5\n",
      "5795/5795 [==============================] - 32s 5ms/step - loss: 0.1975 - acc: 0.9670 - val_loss: 0.1688 - val_acc: 0.9692\n",
      "Epoch 3/5\n",
      "5795/5795 [==============================] - 34s 6ms/step - loss: 0.1539 - acc: 0.9671 - val_loss: 0.1425 - val_acc: 0.9692\n",
      "Epoch 4/5\n",
      "5795/5795 [==============================] - 35s 6ms/step - loss: 0.1219 - acc: 0.9673 - val_loss: 0.1394 - val_acc: 0.9697\n",
      "Epoch 5/5\n",
      "5795/5795 [==============================] - 33s 6ms/step - loss: 0.1052 - acc: 0.9702 - val_loss: 0.1402 - val_acc: 0.9707\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=5,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7, 7, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(train_sequences_padded[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7,  7,  7,  7,  7,  7,  7,  7,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  6,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_sequences_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'MacBook',\n",
       " 'Pro',\n",
       " 'A1278',\n",
       " '13.3',\n",
       " '\"',\n",
       " 'Laptop',\n",
       " '-',\n",
       " 'MD101LL/A',\n",
       " '(',\n",
       " 'June',\n",
       " ',',\n",
       " '2012',\n",
       " ')',\n",
       " '-',\n",
       " 'Full',\n",
       " 'read',\n",
       " 'by',\n",
       " 'eBay',\n",
       " '<URL>',\n",
       " '<URL>']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ---->  I-product(pred label) -----> B-product(true label)\n",
      "MacBook ---->  I-product(pred label) -----> I-product(true label)\n",
      "Pro ---->  I-product(pred label) -----> I-product(true label)\n",
      "A1278 ---->  I-product(pred label) -----> I-product(true label)\n",
      "13.3 ---->  I-other(pred label) -----> I-product(true label)\n",
      "\" ---->  O(pred label) -----> I-product(true label)\n",
      "Laptop ---->  I-other(pred label) -----> I-product(true label)\n",
      "- ---->  O(pred label) -----> I-product(true label)\n",
      "MD101LL/A ---->  O(pred label) -----> I-product(true label)\n",
      "( ---->  O(pred label) -----> O(true label)\n",
      "June ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "2012 ---->  O(pred label) -----> O(true label)\n",
      ") ---->  O(pred label) -----> O(true label)\n",
      "- ---->  O(pred label) -----> O(true label)\n",
      "Full ---->  O(pred label) -----> O(true label)\n",
      "read ---->  O(pred label) -----> O(true label)\n",
      "by ---->  O(pred label) -----> O(true label)\n",
      "eBay ---->  O(pred label) -----> B-company(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = list(model.predict_classes(train_sequences_padded[1].reshape(1,-1)).flatten())\n",
    "y_true_classes = train_tag_sequences_padded[1]\n",
    "tokens = train_sents[1]\n",
    "for y_pred, y_true, token in zip(y_pred_classes, y_true_classes, tokens):\n",
    "    if y_true != 0 or y_pred!= 0:\n",
    "        print(f'{token} ---->  {tag_tokenizer.index_word[y_pred]}(pred label) -----> {tag_tokenizer.index_word[y_true]}(true label)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I-product'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tokenizer.index_word[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, mask_zero=False, input_length=max_len ))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/6\n",
      "5795/5795 [==============================] - 27s 5ms/step - loss: 0.6969 - acc: 0.8691 - val_loss: 0.2103 - val_acc: 0.9691\n",
      "Epoch 2/6\n",
      "5795/5795 [==============================] - 21s 4ms/step - loss: 0.2187 - acc: 0.9650 - val_loss: 0.1950 - val_acc: 0.9692\n",
      "Epoch 3/6\n",
      "5795/5795 [==============================] - 22s 4ms/step - loss: 0.2035 - acc: 0.9668 - val_loss: 0.1825 - val_acc: 0.9692\n",
      "Epoch 4/6\n",
      "5795/5795 [==============================] - 22s 4ms/step - loss: 0.1765 - acc: 0.9670 - val_loss: 0.1579 - val_acc: 0.9692\n",
      "Epoch 5/6\n",
      "5795/5795 [==============================] - 22s 4ms/step - loss: 0.1396 - acc: 0.9671 - val_loss: 0.1434 - val_acc: 0.9694\n",
      "Epoch 6/6\n",
      "5795/5795 [==============================] - 22s 4ms/step - loss: 0.1166 - acc: 0.9686 - val_loss: 0.1441 - val_acc: 0.9700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=6,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "the ---->  O(pred label) -----> O(true label)\n",
      "quest ---->  O(pred label) -----> O(true label)\n",
      "line ---->  O(pred label) -----> O(true label)\n",
      "im ---->  O(pred label) -----> O(true label)\n",
      "assuming ---->  O(pred label) -----> O(true label)\n",
      "it ---->  O(pred label) -----> O(true label)\n",
      "will ---->  O(pred label) -----> O(true label)\n",
      "be ---->  O(pred label) -----> O(true label)\n",
      "the ---->  O(pred label) -----> O(true label)\n",
      "same ---->  O(pred label) -----> O(true label)\n",
      "way ---->  O(pred label) -----> O(true label)\n",
      "with ---->  O(pred label) -----> O(true label)\n",
      "awe ---->  O(pred label) -----> O(true label)\n",
      "thur ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "still ---->  O(pred label) -----> O(true label)\n",
      "perception ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "and ---->  O(pred label) -----> O(true label)\n",
      "what ---->  O(pred label) -----> O(true label)\n",
      "you ---->  O(pred label) -----> O(true label)\n",
      "key ---->  O(pred label) -----> O(true label)\n",
      "off ---->  O(pred label) -----> O(true label)\n",
      "may ---->  O(pred label) -----> O(true label)\n",
      "differ ---->  O(pred label) -----> O(true label)\n",
      "from ---->  O(pred label) -----> O(true label)\n",
      "me ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "Back ---->  O(pred label) -----> O(true label)\n",
      "to ---->  O(pred label) -----> O(true label)\n",
      "Selma ---->  O(pred label) -----> B-person(true label)\n",
      "example ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "iow ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "Amazon ---->  O(pred label) -----> B-product(true label)\n",
      "Kindle ---->  I-product(pred label) -----> I-product(true label)\n",
      "Fire ---->  I-product(pred label) -----> I-product(true label)\n",
      "1st ---->  O(pred label) -----> I-product(true label)\n",
      "Generation ---->  B-geo-loc(pred label) -----> I-product(true label)\n",
      "8GB ---->  I-product(pred label) -----> I-product(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "Wi-Fi ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "7in ---->  O(pred label) -----> O(true label)\n",
      "- ---->  O(pred label) -----> O(true label)\n",
      "Black ---->  B-geo-loc(pred label) -----> O(true label)\n",
      "- ---->  O(pred label) -----> O(true label)\n",
      "Full ---->  O(pred label) -----> O(true label)\n",
      "read ---->  O(pred label) -----> O(true label)\n",
      "by ---->  O(pred label) -----> O(true label)\n",
      "eBay ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "I'll ---->  O(pred label) -----> O(true label)\n",
      "call ---->  O(pred label) -----> O(true label)\n",
      "u ---->  O(pred label) -----> O(true label)\n",
      "after ---->  O(pred label) -----> O(true label)\n",
      "class ---->  O(pred label) -----> O(true label)\n",
      "pooky ---->  O(pred label) -----> O(true label)\n",
      ";D ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(3,7):\n",
    "    y_pred_classes = list(model.predict_classes(train_sequences_padded[i].reshape(1,-1)).flatten())\n",
    "    y_true_classes = train_tag_sequences_padded[i]\n",
    "    tokens = train_sents[i]\n",
    "    for y_pred, y_true, token in zip(y_pred_classes, y_true_classes, tokens):\n",
    "        if y_true != 0 or y_pred!= 0:\n",
    "            print(f'{token} ---->  {tag_tokenizer.index_word[y_pred]}(pred label) -----> {tag_tokenizer.index_word[y_true]}(true label)')\n",
    "    print('======================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import precision_recall_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 200, mask_zero=False, input_length=max_len ))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, recurrent_dropout=0.1)))\n",
    "# model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/4\n",
      "5795/5795 [==============================] - 36s 6ms/step - loss: 0.3594 - acc: 0.9286 - val_loss: 0.1807 - val_acc: 0.9692\n",
      "Epoch 2/4\n",
      "5795/5795 [==============================] - 29s 5ms/step - loss: 0.1577 - acc: 0.9676 - val_loss: 0.1372 - val_acc: 0.9706\n",
      "Epoch 3/4\n",
      "5795/5795 [==============================] - 29s 5ms/step - loss: 0.1093 - acc: 0.9711 - val_loss: 0.1297 - val_acc: 0.9729\n",
      "Epoch 4/4\n",
      "5795/5795 [==============================] - 29s 5ms/step - loss: 0.0829 - acc: 0.9770 - val_loss: 0.1348 - val_acc: 0.9735\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=4,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow ---->  O(pred label) -----> O(true label)\n",
      "!.. ---->  O(pred label) -----> O(true label)\n",
      "Michael ---->  B-person(pred label) -----> B-person(true label)\n",
      "Owen ---->  I-person(pred label) -----> I-person(true label)\n",
      "jwus ---->  O(pred label) -----> O(true label)\n",
      "just ---->  O(pred label) -----> O(true label)\n",
      "ask ---->  O(pred label) -----> O(true label)\n",
      "who ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "think ---->  O(pred label) -----> O(true label)\n",
      "will ---->  O(pred label) -----> O(true label)\n",
      "finish ---->  O(pred label) -----> O(true label)\n",
      "in ---->  O(pred label) -----> O(true label)\n",
      "top ---->  O(pred label) -----> O(true label)\n",
      "four ---->  O(pred label) -----> O(true label)\n",
      "as ---->  O(pred label) -----> O(true label)\n",
      "3rd ---->  O(pred label) -----> O(true label)\n",
      "and ---->  O(pred label) -----> O(true label)\n",
      "4th ---->  O(pred label) -----> O(true label)\n",
      ".. ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "said ---->  O(pred label) -----> O(true label)\n",
      "LFC ---->  B-person(pred label) -----> B-sportsteam(true label)\n",
      "&amp; ---->  O(pred label) -----> O(true label)\n",
      "MUFC ---->  B-geo-loc(pred label) -----> B-sportsteam(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "smh ---->  O(pred label) -----> O(true label)\n",
      ".. ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "is ---->  O(pred label) -----> O(true label)\n",
      "such ---->  O(pred label) -----> O(true label)\n",
      "an ---->  O(pred label) -----> O(true label)\n",
      "bias ---->  O(pred label) -----> O(true label)\n",
      "assole ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "Hell ---->  O(pred label) -----> O(true label)\n",
      "yeh ---->  O(pred label) -----> O(true label)\n",
      "1st ---->  O(pred label) -----> O(true label)\n",
      "day ---->  O(pred label) -----> O(true label)\n",
      "of ---->  O(pred label) -----> O(true label)\n",
      "vacation ---->  O(pred label) -----> O(true label)\n",
      "!!!!! ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "BREACH ---->  O(pred label) -----> O(true label)\n",
      "! ---->  O(pred label) -----> O(true label)\n",
      "CHINA ---->  B-geo-loc(pred label) -----> B-geo-loc(true label)\n",
      "HACKING ---->  O(pred label) -----> O(true label)\n",
      "DESPITE ---->  O(pred label) -----> O(true label)\n",
      "DEAL ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "RT ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      ": ---->  O(pred label) -----> O(true label)\n",
      "When ---->  O(pred label) -----> O(true label)\n",
      "trey ---->  B-person(pred label) -----> B-person(true label)\n",
      "songz ---->  I-person(pred label) -----> I-person(true label)\n",
      "was ---->  O(pred label) -----> O(true label)\n",
      "a ---->  O(pred label) -----> O(true label)\n",
      "kid ---->  O(pred label) -----> O(true label)\n",
      "his ---->  O(pred label) -----> O(true label)\n",
      "mother ---->  O(pred label) -----> O(true label)\n",
      "probably ---->  O(pred label) -----> O(true label)\n",
      "went ---->  O(pred label) -----> O(true label)\n",
      "did ---->  O(pred label) -----> O(true label)\n",
      "you ---->  O(pred label) -----> O(true label)\n",
      "do ---->  O(pred label) -----> O(true label)\n",
      "your ---->  O(pred label) -----> O(true label)\n",
      "homework ---->  O(pred label) -----> O(true label)\n",
      "? ---->  O(pred label) -----> O(true label)\n",
      "And ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "probably ---->  O(pred label) -----> O(true label)\n",
      "went ---->  O(pred label) -----> O(true label)\n",
      "#YUPPP ---->  O(pred label) -----> O(true label)\n",
      "lol ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "C'mon ---->  O(pred label) -----> O(true label)\n",
      "Jeremy ---->  B-other(pred label) -----> B-person(true label)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-a969b59203e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{token} ---->  {tag_tokenizer.index_word[y_pred]}(pred label) -----> {tag_tokenizer.index_word[y_true]}(true label)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'======================================================================'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    y_pred_classes = list(model.predict_classes(train_sequences_padded[i].reshape(1,-1)).flatten())\n",
    "    y_true_classes = train_tag_sequences_padded[i]\n",
    "    tokens = train_sents[i]\n",
    "    for y_pred, y_true, token in zip(y_pred_classes, y_true_classes, tokens):\n",
    "        if y_true != 0 or y_pred!= 0:\n",
    "            print(f'{token} ---->  {tag_tokenizer.index_word[y_pred]}(pred label) -----> {tag_tokenizer.index_word[y_true]}(true label)')\n",
    "    print('======================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9    2    5 ...    0    0    0]\n",
      " [ 622 6026 1742 ...    0    0    0]\n",
      " [ 126  662    2 ...    0    0    0]\n",
      " ...\n",
      " [5952 5953 5954 ...    0    0    0]\n",
      " [ 210 2659   93 ...    0    0    0]\n",
      " [   2    7 1406 ...    0    0    0]]\n",
      "(5795, 40)\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences_padded)\n",
    "print(train_sequences_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1 ...  0  0  0]\n",
      " [10  7  7 ...  0  0  0]\n",
      " [ 1  1  1 ...  0  0  0]\n",
      " ...\n",
      " [ 1  1  1 ...  0  0  0]\n",
      " [ 1  1  1 ...  0  0  0]\n",
      " [ 1  1  1 ...  0  0  0]]\n",
      "(5795, 40)\n"
     ]
    }
   ],
   "source": [
    "print(train_tag_sequences_padded)\n",
    "print(train_tag_sequences_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 200, mask_zero=True, input_length=max_len ))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, recurrent_dropout=0.1)))\n",
    "# model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.2)))\n",
    "model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5795 samples, validate on 724 samples\n",
      "Epoch 1/4\n",
      "5795/5795 [==============================] - 39s 7ms/step - loss: 0.6567 - acc: 0.9168 - val_loss: 0.3863 - val_acc: 0.9265\n",
      "Epoch 2/4\n",
      "5795/5795 [==============================] - 32s 6ms/step - loss: 0.3349 - acc: 0.9251 - val_loss: 0.3313 - val_acc: 0.9294\n",
      "Epoch 3/4\n",
      "5795/5795 [==============================] - 32s 6ms/step - loss: 0.2464 - acc: 0.9334 - val_loss: 0.3242 - val_acc: 0.9311\n",
      "Epoch 4/4\n",
      "5795/5795 [==============================] - 33s 6ms/step - loss: 0.2122 - acc: 0.9407 - val_loss: 0.3239 - val_acc: 0.9331\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_sequences_padded, train_tag_sequences_padded.reshape(-1, max_len, 1),\n",
    "          epochs=4,\n",
    "          validation_data=(val_sequences_padded, val_tag_sequences_padded.reshape(-1, 40, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "<ul>\n",
    "<li>Need to check the role of mask_zero. As per the initial exploration, padding should be given 0 and when the zero is masked then the rnn don't consider those values.\n",
    " <li>As the number of RNN units increases the values that can be memorized increases. Gives significance boost upto some extent. Need to keep the performace of the network as well.\n",
    " <li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow ---->  O(pred label) -----> O(true label)\n",
      "!.. ---->  O(pred label) -----> O(true label)\n",
      "Michael ---->  B-person(pred label) -----> B-person(true label)\n",
      "Owen ---->  I-person(pred label) -----> I-person(true label)\n",
      "jwus ---->  O(pred label) -----> O(true label)\n",
      "just ---->  O(pred label) -----> O(true label)\n",
      "ask ---->  O(pred label) -----> O(true label)\n",
      "who ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "think ---->  O(pred label) -----> O(true label)\n",
      "will ---->  O(pred label) -----> O(true label)\n",
      "finish ---->  O(pred label) -----> O(true label)\n",
      "in ---->  O(pred label) -----> O(true label)\n",
      "top ---->  O(pred label) -----> O(true label)\n",
      "four ---->  O(pred label) -----> O(true label)\n",
      "as ---->  O(pred label) -----> O(true label)\n",
      "3rd ---->  O(pred label) -----> O(true label)\n",
      "and ---->  O(pred label) -----> O(true label)\n",
      "4th ---->  O(pred label) -----> O(true label)\n",
      ".. ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "said ---->  O(pred label) -----> O(true label)\n",
      "LFC ---->  B-person(pred label) -----> B-sportsteam(true label)\n",
      "&amp; ---->  O(pred label) -----> O(true label)\n",
      "MUFC ---->  B-person(pred label) -----> B-sportsteam(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "smh ---->  O(pred label) -----> O(true label)\n",
      ".. ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "is ---->  O(pred label) -----> O(true label)\n",
      "such ---->  O(pred label) -----> O(true label)\n",
      "an ---->  O(pred label) -----> O(true label)\n",
      "bias ---->  O(pred label) -----> O(true label)\n",
      "assole ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "Hell ---->  O(pred label) -----> O(true label)\n",
      "yeh ---->  O(pred label) -----> O(true label)\n",
      "1st ---->  O(pred label) -----> O(true label)\n",
      "day ---->  O(pred label) -----> O(true label)\n",
      "of ---->  O(pred label) -----> O(true label)\n",
      "vacation ---->  O(pred label) -----> O(true label)\n",
      "!!!!! ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "BREACH ---->  O(pred label) -----> O(true label)\n",
      "! ---->  O(pred label) -----> O(true label)\n",
      "CHINA ---->  B-geo-loc(pred label) -----> B-geo-loc(true label)\n",
      "HACKING ---->  O(pred label) -----> O(true label)\n",
      "DESPITE ---->  O(pred label) -----> O(true label)\n",
      "DEAL ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "RT ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      ": ---->  O(pred label) -----> O(true label)\n",
      "When ---->  O(pred label) -----> O(true label)\n",
      "trey ---->  B-person(pred label) -----> B-person(true label)\n",
      "songz ---->  I-person(pred label) -----> I-person(true label)\n",
      "was ---->  O(pred label) -----> O(true label)\n",
      "a ---->  O(pred label) -----> O(true label)\n",
      "kid ---->  O(pred label) -----> O(true label)\n",
      "his ---->  O(pred label) -----> O(true label)\n",
      "mother ---->  O(pred label) -----> O(true label)\n",
      "probably ---->  O(pred label) -----> O(true label)\n",
      "went ---->  O(pred label) -----> O(true label)\n",
      "did ---->  O(pred label) -----> O(true label)\n",
      "you ---->  O(pred label) -----> O(true label)\n",
      "do ---->  O(pred label) -----> O(true label)\n",
      "your ---->  O(pred label) -----> O(true label)\n",
      "homework ---->  O(pred label) -----> O(true label)\n",
      "? ---->  O(pred label) -----> O(true label)\n",
      "And ---->  O(pred label) -----> O(true label)\n",
      "he ---->  O(pred label) -----> O(true label)\n",
      "probably ---->  O(pred label) -----> O(true label)\n",
      "went ---->  O(pred label) -----> O(true label)\n",
      "#YUPPP ---->  O(pred label) -----> O(true label)\n",
      "lol ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "C'mon ---->  O(pred label) -----> O(true label)\n",
      "Jeremy ---->  B-facility(pred label) -----> B-person(true label)\n",
      "Ross ---->  I-facility(pred label) -----> I-person(true label)\n",
      "======================================================================\n",
      "Curious ---->  O(pred label) -----> O(true label)\n",
      "to ---->  O(pred label) -----> O(true label)\n",
      "see ---->  O(pred label) -----> O(true label)\n",
      "who ---->  O(pred label) -----> O(true label)\n",
      "City ---->  B-person(pred label) -----> B-sportsteam(true label)\n",
      "buy ---->  O(pred label) -----> O(true label)\n",
      "in ---->  O(pred label) -----> O(true label)\n",
      "January ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "They ---->  O(pred label) -----> O(true label)\n",
      "need ---->  O(pred label) -----> O(true label)\n",
      "a ---->  O(pred label) -----> O(true label)\n",
      "striker ---->  O(pred label) -----> O(true label)\n",
      "desperately ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "RT ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      ": ---->  O(pred label) -----> O(true label)\n",
      "Your ---->  O(pred label) -----> O(true label)\n",
      "#Cochrane ---->  B-person(pred label) -----> B-product(true label)\n",
      "Eagle ---->  I-person(pred label) -----> I-product(true label)\n",
      "front ---->  O(pred label) -----> O(true label)\n",
      "for ---->  O(pred label) -----> O(true label)\n",
      "April ---->  O(pred label) -----> O(true label)\n",
      "23 ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "2015 ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "Happy ---->  O(pred label) -----> O(true label)\n",
      "Wednesday ---->  O(pred label) -----> O(true label)\n",
      "Off ---->  O(pred label) -----> O(true label)\n",
      "the ---->  O(pred label) -----> O(true label)\n",
      "record ---->  O(pred label) -----> O(true label)\n",
      "for ---->  O(pred label) -----> O(true label)\n",
      "now ---->  O(pred label) -----> O(true label)\n",
      ", ---->  O(pred label) -----> O(true label)\n",
      "show ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "7AM ---->  O(pred label) -----> O(true label)\n",
      "<URL> ---->  O(pred label) -----> O(true label)\n",
      "#blab ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "I ---->  O(pred label) -----> O(true label)\n",
      "want ---->  O(pred label) -----> O(true label)\n",
      "it ---->  O(pred label) -----> O(true label)\n",
      "NOW ---->  O(pred label) -----> O(true label)\n",
      "! ---->  O(pred label) -----> O(true label)\n",
      ";) ---->  O(pred label) -----> O(true label)\n",
      "RT ---->  O(pred label) -----> O(true label)\n",
      ": ---->  O(pred label) -----> O(true label)\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "Pumpkin ---->  B-person(pred label) -----> B-product(true label)\n",
      "Moonshine ---->  I-person(pred label) -----> I-product(true label)\n",
      "has ---->  O(pred label) -----> O(true label)\n",
      "arrived ---->  O(pred label) -----> O(true label)\n",
      "in ---->  O(pred label) -----> O(true label)\n",
      "Nashville ---->  B-geo-loc(pred label) -----> B-geo-loc(true label)\n",
      "-- ---->  O(pred label) -----> O(true label)\n",
      "Give ---->  O(pred label) -----> O(true label)\n",
      "it ---->  O(pred label) -----> O(true label)\n",
      "a ---->  O(pred label) -----> O(true label)\n",
      "week ---->  O(pred label) -----> O(true label)\n",
      "to ---->  O(pred label) -----> O(true label)\n",
      "get ---->  O(pred label) -----> O(true label)\n",
      "it ---->  O(pred label) -----> O(true label)\n",
      "in ---->  O(pred label) -----> O(true label)\n",
      "stores ---->  O(pred label) -----> O(true label)\n",
      ". ---->  O(pred label) -----> O(true label)\n",
      "KY ---->  B-geo-loc(pred label) -----> B-geo-loc(true label)\n",
      "ships ---->  O(pred label) -----> O(true label)\n",
      "next ---->  O(pred label) -----> O(true label)\n",
      "week ---->  O(pred label) -----> O(true label)\n",
      "! ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n",
      "<USR> ---->  O(pred label) -----> O(true label)\n",
      "lol ---->  O(pred label) -----> O(true label)\n",
      "I'm ---->  O(pred label) -----> O(true label)\n",
      "not ---->  O(pred label) -----> O(true label)\n",
      "up ---->  O(pred label) -----> O(true label)\n",
      "to ---->  O(pred label) -----> O(true label)\n",
      "much ---->  O(pred label) -----> O(true label)\n",
      "I'm ---->  O(pred label) -----> O(true label)\n",
      "just ---->  O(pred label) -----> O(true label)\n",
      "off ---->  O(pred label) -----> O(true label)\n",
      "to ---->  O(pred label) -----> O(true label)\n",
      "bed ---->  O(pred label) -----> O(true label)\n",
      "lol ---->  O(pred label) -----> O(true label)\n",
      "had ---->  O(pred label) -----> O(true label)\n",
      "a ---->  O(pred label) -----> O(true label)\n",
      "long ---->  O(pred label) -----> O(true label)\n",
      "day ---->  O(pred label) -----> O(true label)\n",
      "cht ---->  O(pred label) -----> O(true label)\n",
      "tumoz ---->  O(pred label) -----> O(true label)\n",
      ":) ---->  O(pred label) -----> O(true label)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    y_pred_classes = list(model.predict_classes(train_sequences_padded[i].reshape(1,-1)).flatten())\n",
    "    y_true_classes = train_tag_sequences_padded[i]\n",
    "    tokens = train_sents[i]\n",
    "    for y_pred, y_true, token in zip(y_pred_classes, y_true_classes, tokens):\n",
    "        if y_true != 0 or y_pred!= 0:\n",
    "            print(f'{token} ---->  {tag_tokenizer.index_word[y_pred]}(pred label) -----> {tag_tokenizer.index_word[y_true]}(true label)')\n",
    "    print('======================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = sent_tokenizer.texts_to_sequences(test_sents)\n",
    "test_sequences_padded = pad_sequences(test_sequences, padding='post', maxlen=max_len)\n",
    "\n",
    "test_preds = model.predict_classes(test_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds.tolist()\n",
    "pred_tags = []\n",
    "\n",
    "for i, sent in enumerate(test_sents):\n",
    "    sliced_preds = test_preds[i][:len(sent)]\n",
    "    pred_tags_ = [tag_tokenizer.index_word[idx] for idx in sliced_preds]\n",
    "    pred_tags.append(pred_tags_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags_flat = [item for sublist in pred_tags for item in sublist]\n",
    "test_preds_flat = [item for sublist in test_tags for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "musicartist       0.00      0.00      0.00       232\n",
      "    product       0.03      0.02      0.02       318\n",
      "     person       0.14      0.44      0.22       886\n",
      "    company       0.31      0.29      0.30       643\n",
      "      movie       0.00      0.00      0.00        68\n",
      " sportsteam       0.00      0.00      0.00       217\n",
      "   facility       0.10      0.11      0.10       314\n",
      "        loc       0.38      0.43      0.40       996\n",
      "      other       0.14      0.07      0.09       757\n",
      "     tvshow       0.00      0.00      0.00        58\n",
      "\n",
      "  micro avg       0.21      0.24      0.22      4489\n",
      "  macro avg       0.19      0.24      0.20      4489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_preds_flat, pred_tags_flat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
